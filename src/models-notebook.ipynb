{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR-wSOwvmQN5"
   },
   "source": [
    "### **Machine Learning Star Classification**\n",
    "Classification of stars based on their spectral characteristics\n",
    "\n",
    "**Authors:**\n",
    "- *Stefano Quaggio 866504*\n",
    "- *Stefano Andreotti 851596*\n",
    "- *Alberto Varisco 866109*\n",
    "\n",
    "**Classification models used:**\n",
    "- <u>Neural Networks</u>\n",
    "- <u>Support Vector Machine</u>\n",
    "- <u>Decision Tree</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BluXwqmqmQN8"
   },
   "source": [
    "## <u>Initial Analysis</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2087,
     "status": "ok",
     "timestamp": 1707229253143,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "rH_pDntCmQN7",
    "outputId": "b82c95c9-a48c-4e7f-b21e-b44ffdeb68f4"
   },
   "outputs": [],
   "source": [
    "# All libraries imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize,StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import recall_score, accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm,calibration\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#Diamo accesso al nostro google drive che conterrÃ  il dataset che utilizzeremo in questo laboratorio\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_NN_model():\n",
    "    nn_model=Sequential()\n",
    "    nn_model.add(Dense(32, input_dim=input_features, activation='relu'))\n",
    "    nn_model.add(Dense(32, activation='relu'))\n",
    "    nn_model.add(Dropout(0.2))\n",
    "    nn_model.add(Dense(3, activation='softmax'))\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return nn_model\n",
    "\n",
    "# accuracy_stratified: list of classification_report_results as dict\n",
    "# returns dict like scores\n",
    "def extractScoresFromClassificationReport(accuracy_stratified : list):\n",
    "  scores = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1-score': [],\n",
    "  }\n",
    "  for index, val in enumerate(accuracy_stratified):\n",
    "    scores['accuracy'].append(val['accuracy'])\n",
    "    scores['precision'].append(val['macro avg']['precision'])\n",
    "    scores['recall'].append(val['macro avg']['recall'])\n",
    "    scores['f1-score'].append(val['macro avg']['f1-score'])\n",
    "  return scores\n",
    "\n",
    "# Imput list of data\n",
    "# Returns tuple (confidence_interval, mean_value)\n",
    "def calcConfidenceInterval(data : list):\n",
    "  mean_value = np.mean(data)\n",
    "  return (stats.t.interval(0.95, len(data)-1, loc=mean_value, scale=stats.sem(data)), mean_value)\n",
    "\n",
    "\n",
    "# Parameter accuracy_stratified: list of classification_report returned as dict\n",
    "# Run confidence_intervals on metrics output plot, legend print legend\n",
    "def metricGraph(accuracy_stratified : list, legend : bool = True, title = \"Metrics with Confidence Interval (0.95)\") -> None:\n",
    "  scores = extractScoresFromClassificationReport(accuracy_stratified)\n",
    "  \n",
    "  for index, key in enumerate(scores):\n",
    "    val = scores[key]\n",
    "    confidence_interval, mean_value = calcConfidenceInterval(val)\n",
    "    plt.errorbar(index, mean_value, yerr=(confidence_interval[1] - confidence_interval[0])/2, fmt='o', label=key)\n",
    "  # ticks on x axis with labels\n",
    "  plt.xticks(range(0, len(scores.keys())), scores.keys())\n",
    "\n",
    "  # Add labels and title\n",
    "  plt.xlabel('Metrics')\n",
    "  plt.ylabel('Values')\n",
    "  plt.title(title)\n",
    "\n",
    "  # Show the plot\n",
    "  if legend:\n",
    "    plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1707229253547,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "w7glikpkmQN8",
    "outputId": "235a65d0-f6f1-4c24-898d-9300d3dc686e"
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('../dataset/star_classification.csv')\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707229253547,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "xtIU2z4KmQN9",
    "outputId": "bba6e7cb-c7b3-4457-ad85-91953f6b9bee"
   },
   "outputs": [],
   "source": [
    "full_df.info()\n",
    "# Check number of missing values in columns\n",
    "full_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4726,
     "status": "ok",
     "timestamp": 1707229258268,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "RkfiW87amQN-",
    "outputId": "5b1acba7-02ba-42e5-f54a-0f571be0bd5f"
   },
   "outputs": [],
   "source": [
    "full_df.hist(figsize=(18,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1707229258805,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "o9eSChKXmQN-",
    "outputId": "d3795e25-c225-45c9-9146-db1739bd893e"
   },
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder on 'class' column (target) -> 0 = Galaxy, 1 = Quasar, 2 = Star\n",
    "full_df['class'] = label_encoder.fit_transform(full_df['class'])\n",
    "label_mapping = { 'Galaxy': 0, 'Quasar': 1, 'Star': 2 }\n",
    "\n",
    "#Check distribution of target variable\n",
    "sns.countplot(x = full_df['class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1812,
     "status": "ok",
     "timestamp": 1707229260610,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "CAK9LH0jmQN_",
    "outputId": "3ae2b5e2-ccac-42d0-e6df-d69eb253fdd6"
   },
   "outputs": [],
   "source": [
    "# Check correlation between features\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(full_df.corr(), annot=True, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObC7ErmhmQN_"
   },
   "outputs": [],
   "source": [
    "# Remove 'rerun_ID' column as it has only one value and is not useful for classification\n",
    "if 'return_ID' in full_df:\n",
    "  full_df.drop(['rerun_ID'], axis=1, inplace=True)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "x = full_df.drop(['class'], axis=1)\n",
    "y = full_df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dangu69qJbL"
   },
   "source": [
    "## Rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1707226712679,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "dleMNqPMmQN_",
    "outputId": "551439c8-e529-4374-96d9-3f45071f1d2b"
   },
   "outputs": [],
   "source": [
    "# Feature scaling (standardization)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1707226713255,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "lvZDNlQEmQOA",
    "outputId": "fd3b307d-6378-491c-d90d-840ff968d931"
   },
   "outputs": [],
   "source": [
    "# Convert target variable to categorical, as it is a multi-class classification problem\n",
    "y_train_neural = keras.utils.to_categorical(y_train)\n",
    "y_test_neural = keras.utils.to_categorical(y_test)\n",
    "print(X_test.shape, y_test_neural.shape)\n",
    "\n",
    "print(y_train_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "executionInfo": {
     "elapsed": 5608,
     "status": "error",
     "timestamp": 1707226718857,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "DW0vSQfBmQOB",
    "outputId": "20eb3e1c-6ab0-4c5a-d8fa-399adf94ca45"
   },
   "outputs": [],
   "source": [
    "input_features = X_train.shape[1]\n",
    "\n",
    "neural_model=define_NN_model()\n",
    "\n",
    "# Early stopping \n",
    "callback = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = neural_model.fit(X_train, y_train_neural, epochs=50, batch_size=100, verbose=1, validation_data=(X_test, y_test_neural), callbacks=[callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, train_acc = neural_model.evaluate(X_train, y_train_neural, verbose=0)\n",
    "_, test_acc = neural_model.evaluate(X_test, y_test_neural, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "# plot loss during training\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.subplot(121)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(122)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs = neural_model.predict(X_test, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "yhat_classes=np.argmax(yhat_probs,axis=1)\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "\n",
    "y_test_unidimension = [0 if val[0] else 1 if val[1] else 2 for val in y_test_neural]\n",
    "    \n",
    "print(classification_report(y_test_unidimension, yhat_classes, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:45:14.920970200Z",
     "start_time": "2024-02-25T13:45:14.740216Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(neural_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "epochs = 30\n",
    "folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "nn_k_fold_metrics = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "fold_neural_model=define_NN_model()\n",
    "fold_neural_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(x, y)):\n",
    "    # split data with corss validation indexes\n",
    "    X_t, X_valid = x.iloc[train_idx], x.iloc[valid_idx]\n",
    "    X_t = scaler.fit_transform(X_t)\n",
    "    X_valid = scaler.fit_transform(X_valid)\n",
    "    y_t, y_valid = y[train_idx], y[valid_idx]\n",
    "    y_valid = keras.utils.to_categorical(y_valid)\n",
    "    y_t = keras.utils.to_categorical(y_t)\n",
    "\n",
    "    # train model on fold\n",
    "    history = fold_neural_model.fit(X_t, y_t, epochs=epochs, batch_size=100, verbose=1, validation_data=(X_valid, y_valid), callbacks=[callback])\n",
    "\n",
    "    # predict probabilities for test set\n",
    "    y_pred_fold_neural_model = fold_neural_model.predict(X_valid, verbose=0)\n",
    "    # predict crisp classes for test set\n",
    "    yhat_classes=np.argmax(y_pred_fold_neural_model, axis=1)\n",
    "    # reduce to 1d array\n",
    "    y_pred_fold_neural_model = y_pred_fold_neural_model[:, 0]\n",
    "\n",
    "    y_test_unidimension = [0 if val[0] else 1 if val[1] else 2 for val in y_valid]\n",
    "        \n",
    "    nn_k_fold_metrics.append(classification_report(y_test_unidimension, yhat_classes, target_names=label_mapping.keys(), output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricGraph(nn_k_fold_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets\n",
    "x = full_df.drop(['class'], axis=1)\n",
    "y = full_df['class']\n",
    "# Feature scaling (standardization)\n",
    "# NEEDED for LinearSVC\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "x_scaled = pd.DataFrame(x_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2)\n",
    "\n",
    "# Print class distribution over training set\n",
    "print(f\"#0: {np.sum(y_train == 0)}\")\n",
    "print(f\"#1: {np.sum(y_train == 1)}\")\n",
    "print(f\"#2: {np.sum(y_train == 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81569,
     "status": "ok",
     "timestamp": 1707230826021,
     "user": {
      "displayName": "Alberto Varisco",
      "userId": "14644811473278569331"
     },
     "user_tz": -60
    },
    "id": "62UaENtnwPYq",
    "outputId": "bd25c865-2b5c-4cd4-fbe6-150b24c462ba"
   },
   "outputs": [],
   "source": [
    "# Crea il classificatore SVM\n",
    "svm_model =  OneVsRestClassifier(svm.LinearSVC(dual=\"auto\", tol=1e-5, C=1))\n",
    "# per avere probability_distribution sv = CalibratedClassifierCV(sv) (curva roc)\n",
    "svm_model = calibration.CalibratedClassifierCV(svm_model) \n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# calcolo dell'accuratezza\n",
    "# label_mapping dict: Galaxy = 0, Quasar = 1, Star = 2\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"Accuratezza: {accuracy}\\n\\n\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#binarize the y_values\n",
    "y_pred_prob_svm = svm_model.predict_proba(X_test)\n",
    "classes=np.unique(y_test)\n",
    "y_test_binarized=label_binarize(y_test,classes=classes)\n",
    "\n",
    "# roc curve for classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "roc_auc = dict()\n",
    "\n",
    "n_class = classes.shape[0]\n",
    "\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_test_binarized[:,i], y_pred_prob_svm[:,i])\n",
    "    roc_auc[i] = roc_auc_score(y_test_binarized[:,i], y_pred_prob_svm[:,i])\n",
    "    \n",
    "# plotting    \n",
    "plt.plot(fpr[0], tpr[0],label='Galaxy vs Rest (AUC = %0.3f)'%(roc_auc[0]))\n",
    "plt.plot(fpr[1], tpr[1], label='Quasar vs Rest (AUC = %0.3f)'%(roc_auc[1]))\n",
    "plt.plot(fpr[2], tpr[2], label='Stars vs Rest (AUC = %0.3f)'%(roc_auc[2]))\n",
    "\n",
    "plt.plot([0,1],[0,1],'b--')\n",
    "\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap=\"Blues\", xticklabels=list((\"Galaxy\", \"Quasar\", \"Star\")), yticklabels=list((\"Galaxy\", \"Quasar\", \"Star\")))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Confusion Matrix SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "svm_k_fold_metrics = []\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(x_scaled, y)):\n",
    "  # split data with corss validation indexes\n",
    "  X_train, X_valid = x_scaled.iloc[train_idx], x_scaled.iloc[valid_idx]\n",
    "  y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "  # train model on fold\n",
    "  svm_model.fit(X_train, y_train)\n",
    "  y_pred_svm_fold = svm_model.predict(X_valid)\n",
    "  # save scores of fold\n",
    "  svm_k_fold_metrics.append(classification_report(y_valid, y_pred_svm_fold, target_names=label_mapping.keys(), output_dict=True))\n",
    "\n",
    "metricGraph(svm_k_fold_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameters grid\n",
    "param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "              'max_depth': [9, 11, 13, 15, 17],\n",
    "              'min_samples_leaf': [20, 40, 60],\n",
    "              'min_samples_split': [40, 60, 80]\n",
    "              }\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "# Use 5-fold cross validation\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "decision_tree_model = DecisionTreeClassifier(random_state = 1000, criterion = 'entropy', max_depth=15, min_samples_leaf=20, min_samples_split=80, class_weight = {0:1, 1:1, 2:2})\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "y_pred_dt = decision_tree_model.predict(X_test)\n",
    "\n",
    "dtree_score = recall_score(y_test, y_pred_dt, average='weighted')\n",
    "print(dtree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print Tree\n",
    "fig, ax = plt.subplots(figsize=(150, 100))\n",
    "plot_tree(decision_tree_model, filled=True, ax=ax)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_prob_dt = decision_tree_model.predict_proba(X_test)\n",
    "classes=np.unique(y_test)\n",
    "y_test_binarized=label_binarize(y_test,classes=classes)\n",
    "\n",
    "# ROC curve for classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "roc_auc_dt = dict()\n",
    "n_class = 3\n",
    "\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_test_binarized[:,i], y_pred_prob_dt[:,i])\n",
    "    roc_auc_dt[i] = roc_auc_score(y_test_binarized[:,i], y_pred_prob_dt[:,i])\n",
    "    \n",
    "# Plotting    \n",
    "plt.plot(fpr[0], tpr[0],label='Galaxy vs Rest (AUC = %0.3f)'%(roc_auc_dt[0]))\n",
    "plt.plot(fpr[1], tpr[1], label='Quasar vs Rest (AUC = %0.3f)'%(roc_auc_dt[1]))\n",
    "plt.plot(fpr[2], tpr[2], label='Stars vs Rest (AUC = %0.3f)'%(roc_auc_dt[2]))\n",
    "\n",
    "plt.plot([0,1],[0,1],'b--')\n",
    "\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap=\"Blues\", xticklabels=list((\"Galaxy\", \"Quasar\", \"Star\")), yticklabels=list((\"Galaxy\", \"Quasar\", \"Star\")))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Confusion Matrix Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complexity vs Accuracy\n",
    "path = decision_tree_model.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "# Use different complexity values\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Train with different complexity\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "for complexity in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(max_depth=3, ccp_alpha=complexity)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_accuracy.append(clf.score(X_train, y_train))\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "# Make plots\n",
    "plt.plot(ccp_alphas, train_accuracy, label='Training Accuracy')\n",
    "plt.plot(ccp_alphas, test_accuracy, label='Test Accuracy')\n",
    "plt.xlabel('Complexity Parameter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Complexity Parameter')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post pruning\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\n",
    "    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "        clfs[-1].tree_.node_count, ccp_alphas[-1]\n",
    "    )\n",
    ")\n",
    "\n",
    "clfs = clfs[:-1]\n",
    "complexity_values = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].plot(complexity_values, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"Alpha\")\n",
    "ax[0].set_ylabel(\"Node number\")\n",
    "ax[0].set_title(\"Node number vs Alpha\")\n",
    "ax[1].plot(complexity_values, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"Alpha\")\n",
    "ax[1].set_ylabel(\"Tree depth\")\n",
    "ax[1].set_title(\"Depth vs Alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "tree_k_fold_metrics = []\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(x, y)):\n",
    "  # Split data with corss validation indexes\n",
    "  X_train, X_valid = x_scaled.iloc[train_idx], x_scaled.iloc[valid_idx]\n",
    "  y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "  # Train model on fold\n",
    "  decision_tree_model.fit(X_train, y_train)\n",
    "  y_pred_dt_fold = decision_tree_model.predict(X_valid)\n",
    "  # Save scores of fold\n",
    "  tree_k_fold_metrics.append(classification_report(y_valid, y_pred_dt_fold, target_names=label_mapping.keys(), output_dict=True))\n",
    "\n",
    "metricGraph(tree_k_fold_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_unidimension, yhat_classes, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_scores = extractScoresFromClassificationReport(nn_k_fold_metrics)\n",
    "svm_scores = extractScoresFromClassificationReport(svm_k_fold_metrics)\n",
    "tree_score = extractScoresFromClassificationReport(tree_k_fold_metrics)\n",
    "\n",
    "for key in nn_scores:\n",
    "  nn_confint, nn_mean_val = calcConfidenceInterval(nn_scores[key])\n",
    "  plt.errorbar(0, nn_mean_val, yerr=(nn_confint[1] - nn_confint[0])/2, fmt='o', label='nn')\n",
    "\n",
    "  svm_confint, svm_mean_val = calcConfidenceInterval(svm_scores[key])\n",
    "  plt.errorbar(1, svm_mean_val, yerr=(svm_confint[1] - svm_confint[0])/2, fmt='o', label='svm')\n",
    "\n",
    "  tree_confint, tree_mean_val = calcConfidenceInterval(tree_score[key])\n",
    "  plt.errorbar(2, tree_mean_val, yerr=(tree_confint[1] - tree_confint[0])/2, fmt='o', label='tree')\n",
    "\n",
    "  # ticks on x axis with labels\n",
    "  plt.xticks(range(0, 3), ['nn', 'svm', 'tree'])\n",
    "\n",
    "  # Add labels and title\n",
    "  plt.xlabel('Metrics')\n",
    "  plt.ylabel('Values')\n",
    "  plt.title(f\"Comparing {key} metric between models\")\n",
    "  # Show the plot\n",
    "  plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BluXwqmqmQN8",
    "2dangu69qJbL"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
